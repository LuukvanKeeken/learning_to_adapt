Logging to /workspace/data/mb_mpc/MBMPC_cartpole_15itr_taskNone_run3

 ---------------- Iteration 0 ----------------
Obtaining random samples from the environment...
Processing environment samples...
Training dynamics model for 100 epochs ...
Training DynamicsModel - finished epoch 0 --train loss: 0.3910  valid loss: 0.1215  valid_loss_mov_avg: 0.1816  epoch time: 0.10
Training DynamicsModel - finished epoch 1 --train loss: 0.0648  valid loss: 0.0482  valid_loss_mov_avg: 0.1803  epoch time: 0.03
Training DynamicsModel - finished epoch 2 --train loss: 0.0286  valid loss: 0.0117  valid_loss_mov_avg: 0.1786  epoch time: 0.04
Training DynamicsModel - finished epoch 3 --train loss: 0.0139  valid loss: 0.0057  valid_loss_mov_avg: 0.1769  epoch time: 0.04
Training DynamicsModel - finished epoch 4 --train loss: 0.0078  valid loss: 0.0035  valid_loss_mov_avg: 0.1751  epoch time: 0.04
Training DynamicsModel - finished epoch 5 --train loss: 0.0042  valid loss: 0.0036  valid_loss_mov_avg: 0.1734  epoch time: 0.04
Training DynamicsModel - finished epoch 6 --train loss: 0.0030  valid loss: 0.0030  valid_loss_mov_avg: 0.1717  epoch time: 0.04
Training DynamicsModel - finished epoch 7 --train loss: 0.0023  valid loss: 0.0024  valid_loss_mov_avg: 0.1700  epoch time: 0.04
Training DynamicsModel - finished epoch 8 --train loss: 0.0018  valid loss: 0.0014  valid_loss_mov_avg: 0.1683  epoch time: 0.04
Training DynamicsModel - finished epoch 9 --train loss: 0.0013  valid loss: 0.0011  valid_loss_mov_avg: 0.1667  epoch time: 0.04
Training DynamicsModel - finished epoch 10 --train loss: 0.0010  valid loss: 0.0009  valid_loss_mov_avg: 0.1650  epoch time: 0.03
Training DynamicsModel - finished epoch 11 --train loss: 0.0009  valid loss: 0.0008  valid_loss_mov_avg: 0.1634  epoch time: 0.04
Training DynamicsModel - finished epoch 12 --train loss: 0.0008  valid loss: 0.0007  valid_loss_mov_avg: 0.1617  epoch time: 0.04
Training DynamicsModel - finished epoch 13 --train loss: 0.0007  valid loss: 0.0006  valid_loss_mov_avg: 0.1601  epoch time: 0.04
Training DynamicsModel - finished epoch 14 --train loss: 0.0006  valid loss: 0.0005  valid_loss_mov_avg: 0.1585  epoch time: 0.04
Training DynamicsModel - finished epoch 15 --train loss: 0.0005  valid loss: 0.0005  valid_loss_mov_avg: 0.1569  epoch time: 0.04
Training DynamicsModel - finished epoch 16 --train loss: 0.0005  valid loss: 0.0004  valid_loss_mov_avg: 0.1554  epoch time: 0.04
Training DynamicsModel - finished epoch 17 --train loss: 0.0004  valid loss: 0.0004  valid_loss_mov_avg: 0.1538  epoch time: 0.04
Training DynamicsModel - finished epoch 18 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.1523  epoch time: 0.04
Training DynamicsModel - finished epoch 19 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.1508  epoch time: 0.04
Training DynamicsModel - finished epoch 20 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.1493  epoch time: 0.04
Training DynamicsModel - finished epoch 21 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.1478  epoch time: 0.04
Training DynamicsModel - finished epoch 22 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.1463  epoch time: 0.04
Training DynamicsModel - finished epoch 23 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.1448  epoch time: 0.04
Training DynamicsModel - finished epoch 24 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.1434  epoch time: 0.04
Training DynamicsModel - finished epoch 25 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.1420  epoch time: 0.04
Training DynamicsModel - finished epoch 26 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.1405  epoch time: 0.04
Training DynamicsModel - finished epoch 27 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.1391  epoch time: 0.04
Training DynamicsModel - finished epoch 28 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.1378  epoch time: 0.04
Training DynamicsModel - finished epoch 29 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.1364  epoch time: 0.04
Training DynamicsModel - finished epoch 30 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.1350  epoch time: 0.04
Training DynamicsModel - finished epoch 31 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.1337  epoch time: 0.04
Training DynamicsModel - finished epoch 32 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.1323  epoch time: 0.04
Training DynamicsModel - finished epoch 33 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.1310  epoch time: 0.04
Training DynamicsModel - finished epoch 34 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.1297  epoch time: 0.04
Training DynamicsModel - finished epoch 35 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.1284  epoch time: 0.04
Training DynamicsModel - finished epoch 36 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.1271  epoch time: 0.04
Training DynamicsModel - finished epoch 37 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.1258  epoch time: 0.04
Training DynamicsModel - finished epoch 38 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.1246  epoch time: 0.04
Training DynamicsModel - finished epoch 39 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.1233  epoch time: 0.04
Training DynamicsModel - finished epoch 40 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.1221  epoch time: 0.04
Training DynamicsModel - finished epoch 41 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.1209  epoch time: 0.04
Training DynamicsModel - finished epoch 42 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.1197  epoch time: 0.04
Training DynamicsModel - finished epoch 43 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.1185  epoch time: 0.04
Training DynamicsModel - finished epoch 44 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.1173  epoch time: 0.04
Training DynamicsModel - finished epoch 45 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.1161  epoch time: 0.04
Training DynamicsModel - finished epoch 46 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.1150  epoch time: 0.04
Training DynamicsModel - finished epoch 47 --train loss: 0.0000  valid loss: 0.0000  valid_loss_mov_avg: 0.1138  epoch time: 0.04
Training DynamicsModel - finished epoch 48 --train loss: 0.0000  valid loss: 0.0000  valid_loss_mov_avg: 0.1127  epoch time: 0.04
Training DynamicsModel - finished epoch 49 --train loss: 0.0000  valid loss: 0.0000  valid_loss_mov_avg: 0.1116  epoch time: 0.04
Training DynamicsModel - finished epoch 50 --train loss: 0.0000  valid loss: 0.0000  valid_loss_mov_avg: 0.1104  epoch time: 0.04
Training DynamicsModel - finished epoch 51 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.1093  epoch time: 0.04
Training DynamicsModel - finished epoch 52 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.1082  epoch time: 0.04
Training DynamicsModel - finished epoch 53 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.1072  epoch time: 0.04
Training DynamicsModel - finished epoch 54 --train loss: 0.0000  valid loss: 0.0000  valid_loss_mov_avg: 0.1061  epoch time: 0.04
Training DynamicsModel - finished epoch 55 --train loss: 0.0000  valid loss: 0.0000  valid_loss_mov_avg: 0.1050  epoch time: 0.04
Training DynamicsModel - finished epoch 56 --train loss: 0.0000  valid loss: 0.0000  valid_loss_mov_avg: 0.1040  epoch time: 0.04
Training DynamicsModel - finished epoch 57 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.1029  epoch time: 0.04
Training DynamicsModel - finished epoch 58 --train loss: 0.0000  valid loss: 0.0000  valid_loss_mov_avg: 0.1019  epoch time: 0.04
Training DynamicsModel - finished epoch 59 --train loss: 0.0000  valid loss: 0.0000  valid_loss_mov_avg: 0.1009  epoch time: 0.04
Training DynamicsModel - finished epoch 60 --train loss: 0.0000  valid loss: 0.0000  valid_loss_mov_avg: 0.0999  epoch time: 0.04
Training DynamicsModel - finished epoch 61 --train loss: 0.0000  valid loss: 0.0000  valid_loss_mov_avg: 0.0989  epoch time: 0.04
Training DynamicsModel - finished epoch 62 --train loss: 0.0000  valid loss: 0.0000  valid_loss_mov_avg: 0.0979  epoch time: 0.04
Training DynamicsModel - finished epoch 63 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.0969  epoch time: 0.04
Training DynamicsModel - finished epoch 64 --train loss: 0.0001  valid loss: 0.0000  valid_loss_mov_avg: 0.0960  epoch time: 0.04
Training DynamicsModel - finished epoch 65 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.0950  epoch time: 0.04
Training DynamicsModel - finished epoch 66 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.0940  epoch time: 0.04
Training DynamicsModel - finished epoch 67 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0931  epoch time: 0.04
Training DynamicsModel - finished epoch 68 --train loss: 0.0000  valid loss: 0.0000  valid_loss_mov_avg: 0.0922  epoch time: 0.04
Training DynamicsModel - finished epoch 69 --train loss: 0.0000  valid loss: 0.0000  valid_loss_mov_avg: 0.0913  epoch time: 0.04
Training DynamicsModel - finished epoch 70 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.0903  epoch time: 0.04
Training DynamicsModel - finished epoch 71 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.0894  epoch time: 0.04
Training DynamicsModel - finished epoch 72 --train loss: 0.0000  valid loss: 0.0000  valid_loss_mov_avg: 0.0885  epoch time: 0.04
Training DynamicsModel - finished epoch 73 --train loss: 0.0000  valid loss: 0.0000  valid_loss_mov_avg: 0.0877  epoch time: 0.04
Training DynamicsModel - finished epoch 74 --train loss: 0.0000  valid loss: 0.0000  valid_loss_mov_avg: 0.0868  epoch time: 0.04
Training DynamicsModel - finished epoch 75 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.0859  epoch time: 0.04
Training DynamicsModel - finished epoch 76 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.0851  epoch time: 0.04
Training DynamicsModel - finished epoch 77 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0842  epoch time: 0.04
Training DynamicsModel - finished epoch 78 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0834  epoch time: 0.04
Training DynamicsModel - finished epoch 79 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0825  epoch time: 0.04
Training DynamicsModel - finished epoch 80 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0817  epoch time: 0.04
Training DynamicsModel - finished epoch 81 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0809  epoch time: 0.04
Training DynamicsModel - finished epoch 82 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0801  epoch time: 0.04
Training DynamicsModel - finished epoch 83 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0793  epoch time: 0.04
Training DynamicsModel - finished epoch 84 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0785  epoch time: 0.04
Training DynamicsModel - finished epoch 85 --train loss: 0.0000  valid loss: 0.0001  valid_loss_mov_avg: 0.0777  epoch time: 0.04
Training DynamicsModel - finished epoch 86 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0769  epoch time: 0.04
Training DynamicsModel - finished epoch 87 --train loss: 0.0002  valid loss: 0.0004  valid_loss_mov_avg: 0.0762  epoch time: 0.04
Training DynamicsModel - finished epoch 88 --train loss: 0.0004  valid loss: 0.0007  valid_loss_mov_avg: 0.0754  epoch time: 0.04
Training DynamicsModel - finished epoch 89 --train loss: 0.0006  valid loss: 0.0003  valid_loss_mov_avg: 0.0747  epoch time: 0.04
Training DynamicsModel - finished epoch 90 --train loss: 0.0016  valid loss: 0.0030  valid_loss_mov_avg: 0.0739  epoch time: 0.04
Training DynamicsModel - finished epoch 91 --train loss: 0.0026  valid loss: 0.0048  valid_loss_mov_avg: 0.0733  epoch time: 0.04
Training DynamicsModel - finished epoch 92 --train loss: 0.0036  valid loss: 0.0015  valid_loss_mov_avg: 0.0725  epoch time: 0.04
Training DynamicsModel - finished epoch 93 --train loss: 0.0019  valid loss: 0.0007  valid_loss_mov_avg: 0.0718  epoch time: 0.04
Training DynamicsModel - finished epoch 94 --train loss: 0.0008  valid loss: 0.0006  valid_loss_mov_avg: 0.0711  epoch time: 0.04
Training DynamicsModel - finished epoch 95 --train loss: 0.0005  valid loss: 0.0003  valid_loss_mov_avg: 0.0704  epoch time: 0.04
Training DynamicsModel - finished epoch 96 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.0697  epoch time: 0.04
Training DynamicsModel - finished epoch 97 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0690  epoch time: 0.04
Training DynamicsModel - finished epoch 98 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0683  epoch time: 0.04
Training DynamicsModel - finished epoch 99 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0676  epoch time: 0.04
Stopping Training of Model since it reached max epochs
Evaluating agent...
Saving snapshot...
Saved
--------------------------------------
| AverageDiscountedReturn | 19.4     |
| AverageReturn           | 22       |
| AvgModelEpochTime       | 0.0385   |
| EnvExecTime             | 0.134    |
| Epochs                  | 99       |
| Eval-AverageReturn      | 163      |
| Itr                     | 0        |
| ItrTime                 | 30.9     |
| MaxReturn               | 63       |
| MinReturn               | 9        |
| NumTrajs                | 92       |
| PolicyExecTime          | 0.0282   |
| StdReturn               | 10.5     |
| Time                    | 30.9     |
| Time-AgentEval          | 26.1     |
| Time-EnvSampleProc      | 0.00405  |
| Time-EnvSampling        | 0.182    |
| Time-ModelFit           | 4.61     |
| n_timesteps             | 2000     |
--------------------------------------

 ---------------- Iteration 1 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 100 epochs ...
Training DynamicsModel - finished epoch 0 --train loss: 0.0014  valid loss: 0.0011  valid_loss_mov_avg: 0.0016  epoch time: 0.06
Training DynamicsModel - finished epoch 1 --train loss: 0.0012  valid loss: 0.0005  valid_loss_mov_avg: 0.0016  epoch time: 0.07
Training DynamicsModel - finished epoch 2 --train loss: 0.0005  valid loss: 0.0004  valid_loss_mov_avg: 0.0016  epoch time: 0.07
Training DynamicsModel - finished epoch 3 --train loss: 0.0003  valid loss: 0.0002  valid_loss_mov_avg: 0.0016  epoch time: 0.07
Training DynamicsModel - finished epoch 4 --train loss: 0.0004  valid loss: 0.0003  valid_loss_mov_avg: 0.0016  epoch time: 0.07
Training DynamicsModel - finished epoch 5 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.0015  epoch time: 0.06
Training DynamicsModel - finished epoch 6 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0015  epoch time: 0.07
Training DynamicsModel - finished epoch 7 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0015  epoch time: 0.07
Training DynamicsModel - finished epoch 8 --train loss: 0.0003  valid loss: 0.0005  valid_loss_mov_avg: 0.0015  epoch time: 0.06
Training DynamicsModel - finished epoch 9 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.0015  epoch time: 0.07
Training DynamicsModel - finished epoch 10 --train loss: 0.0003  valid loss: 0.0004  valid_loss_mov_avg: 0.0015  epoch time: 0.07
Training DynamicsModel - finished epoch 11 --train loss: 0.0004  valid loss: 0.0008  valid_loss_mov_avg: 0.0015  epoch time: 0.07
Training DynamicsModel - finished epoch 12 --train loss: 0.0005  valid loss: 0.0004  valid_loss_mov_avg: 0.0015  epoch time: 0.07
Training DynamicsModel - finished epoch 13 --train loss: 0.0009  valid loss: 0.0029  valid_loss_mov_avg: 0.0015  epoch time: 0.07
Stopping Training of Model since its valid_loss_rolling_average increased
Evaluating agent...
Saving snapshot...
Saved
--------------------------------------
| AverageDiscountedReturn | 76.9     |
| AverageReturn           | 157      |
| AvgModelEpochTime       | 0.0665   |
| EnvExecTime             | 0.368    |
| Epochs                  | 13       |
| Eval-AverageReturn      | 145      |
| Itr                     | 1        |
| ItrTime                 | 36.5     |
| MaxReturn               | 200      |
| MinReturn               | 56       |
| NumTrajs                | 13       |
| PolicyExecTime          | 11.5     |
| StdReturn               | 45.8     |
| Time                    | 67.4     |
| Time-AgentEval          | 23.5     |
| Time-EnvSampleProc      | 0.00181  |
| Time-EnvSampling        | 12       |
| Time-ModelFit           | 1.04     |
| n_timesteps             | 4000     |
--------------------------------------

 ---------------- Iteration 2 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 100 epochs ...
Training DynamicsModel - finished epoch 0 --train loss: 0.0010  valid loss: 0.0005  valid_loss_mov_avg: 0.0007  epoch time: 0.10
Training DynamicsModel - finished epoch 1 --train loss: 0.0004  valid loss: 0.0002  valid_loss_mov_avg: 0.0007  epoch time: 0.10
Training DynamicsModel - finished epoch 2 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.0007  epoch time: 0.10
Training DynamicsModel - finished epoch 3 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0007  epoch time: 0.10
Training DynamicsModel - finished epoch 4 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0007  epoch time: 0.11
Training DynamicsModel - finished epoch 5 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0007  epoch time: 0.10
Training DynamicsModel - finished epoch 6 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0007  epoch time: 0.11
Training DynamicsModel - finished epoch 7 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0007  epoch time: 0.10
Training DynamicsModel - finished epoch 8 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0007  epoch time: 0.10
Training DynamicsModel - finished epoch 9 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0007  epoch time: 0.10
Training DynamicsModel - finished epoch 10 --train loss: 0.0001  valid loss: 0.0003  valid_loss_mov_avg: 0.0007  epoch time: 0.10
Training DynamicsModel - finished epoch 11 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0007  epoch time: 0.10
Training DynamicsModel - finished epoch 12 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0007  epoch time: 0.10
Training DynamicsModel - finished epoch 13 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0007  epoch time: 0.10
Training DynamicsModel - finished epoch 14 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0007  epoch time: 0.10
Training DynamicsModel - finished epoch 15 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0007  epoch time: 0.10
Training DynamicsModel - finished epoch 16 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0007  epoch time: 0.10
Training DynamicsModel - finished epoch 17 --train loss: 0.0003  valid loss: 0.0001  valid_loss_mov_avg: 0.0006  epoch time: 0.10
Training DynamicsModel - finished epoch 18 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0006  epoch time: 0.10
Training DynamicsModel - finished epoch 19 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0006  epoch time: 0.10
Training DynamicsModel - finished epoch 20 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0006  epoch time: 0.10
Training DynamicsModel - finished epoch 21 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0006  epoch time: 0.10
Training DynamicsModel - finished epoch 22 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0006  epoch time: 0.10
Training DynamicsModel - finished epoch 23 --train loss: 0.0003  valid loss: 0.0004  valid_loss_mov_avg: 0.0006  epoch time: 0.10
Training DynamicsModel - finished epoch 24 --train loss: 0.0005  valid loss: 0.0003  valid_loss_mov_avg: 0.0006  epoch time: 0.10
Training DynamicsModel - finished epoch 25 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.0006  epoch time: 0.10
Training DynamicsModel - finished epoch 26 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0006  epoch time: 0.11
Training DynamicsModel - finished epoch 27 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0006  epoch time: 0.10
Training DynamicsModel - finished epoch 28 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0006  epoch time: 0.10
Training DynamicsModel - finished epoch 29 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0006  epoch time: 0.10
Training DynamicsModel - finished epoch 30 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0006  epoch time: 0.10
Training DynamicsModel - finished epoch 31 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0006  epoch time: 0.10
Training DynamicsModel - finished epoch 32 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0006  epoch time: 0.10
Training DynamicsModel - finished epoch 33 --train loss: 0.0004  valid loss: 0.0003  valid_loss_mov_avg: 0.0006  epoch time: 0.10
Training DynamicsModel - finished epoch 34 --train loss: 0.0004  valid loss: 0.0007  valid_loss_mov_avg: 0.0006  epoch time: 0.10
Stopping Training of Model since its valid_loss_rolling_average increased
Evaluating agent...
Saving snapshot...
Saved
--------------------------------------
| AverageDiscountedReturn | 78       |
| AverageReturn           | 166      |
| AvgModelEpochTime       | 0.101    |
| EnvExecTime             | 0.359    |
| Epochs                  | 34       |
| Eval-AverageReturn      | 175      |
| Itr                     | 2        |
| ItrTime                 | 44       |
| MaxReturn               | 200      |
| MinReturn               | 57       |
| NumTrajs                | 13       |
| PolicyExecTime          | 11.3     |
| StdReturn               | 49.6     |
| Time                    | 111      |
| Time-AgentEval          | 28.5     |
| Time-EnvSampleProc      | 0.00193  |
| Time-EnvSampling        | 11.7     |
| Time-ModelFit           | 3.81     |
| n_timesteps             | 6000     |
--------------------------------------

 ---------------- Iteration 3 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 100 epochs ...
Training DynamicsModel - finished epoch 0 --train loss: 0.0006  valid loss: 0.0003  valid_loss_mov_avg: 0.0005  epoch time: 0.12
Training DynamicsModel - finished epoch 1 --train loss: 0.0004  valid loss: 0.0002  valid_loss_mov_avg: 0.0005  epoch time: 0.13
Training DynamicsModel - finished epoch 2 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0005  epoch time: 0.13
Training DynamicsModel - finished epoch 3 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.13
Training DynamicsModel - finished epoch 4 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.11
Training DynamicsModel - finished epoch 5 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0005  epoch time: 0.11
Training DynamicsModel - finished epoch 6 --train loss: 0.0003  valid loss: 0.0005  valid_loss_mov_avg: 0.0005  epoch time: 0.12
Training DynamicsModel - finished epoch 7 --train loss: 0.0003  valid loss: 0.0004  valid_loss_mov_avg: 0.0005  epoch time: 0.13
Training DynamicsModel - finished epoch 8 --train loss: 0.0004  valid loss: 0.0005  valid_loss_mov_avg: 0.0005  epoch time: 0.13
Training DynamicsModel - finished epoch 9 --train loss: 0.0005  valid loss: 0.0002  valid_loss_mov_avg: 0.0005  epoch time: 0.13
Training DynamicsModel - finished epoch 10 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0005  epoch time: 0.13
Training DynamicsModel - finished epoch 11 --train loss: 0.0002  valid loss: 0.0004  valid_loss_mov_avg: 0.0005  epoch time: 0.13
Training DynamicsModel - finished epoch 12 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.13
Training DynamicsModel - finished epoch 13 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0005  epoch time: 0.13
Training DynamicsModel - finished epoch 14 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.12
Training DynamicsModel - finished epoch 15 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.14
Training DynamicsModel - finished epoch 16 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0005  epoch time: 0.12
Training DynamicsModel - finished epoch 17 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.13
Training DynamicsModel - finished epoch 18 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.12
Training DynamicsModel - finished epoch 19 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0005  epoch time: 0.13
Training DynamicsModel - finished epoch 20 --train loss: 0.0003  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.13
Training DynamicsModel - finished epoch 21 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.12
Training DynamicsModel - finished epoch 22 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0005  epoch time: 0.13
Training DynamicsModel - finished epoch 23 --train loss: 0.0003  valid loss: 0.0005  valid_loss_mov_avg: 0.0005  epoch time: 0.13
Stopping Training of Model since its valid_loss_rolling_average increased
Evaluating agent...
Saving snapshot...
Saved
--------------------------------------
| AverageDiscountedReturn | 83.4     |
| AverageReturn           | 182      |
| AvgModelEpochTime       | 0.127    |
| EnvExecTime             | 0.313    |
| Epochs                  | 23       |
| Eval-AverageReturn      | 174      |
| Itr                     | 3        |
| ItrTime                 | 41.9     |
| MaxReturn               | 200      |
| MinReturn               | 130      |
| NumTrajs                | 11       |
| PolicyExecTime          | 9.89     |
| StdReturn               | 26.2     |
| Time                    | 153      |
| Time-AgentEval          | 28.4     |
| Time-EnvSampleProc      | 0.00171  |
| Time-EnvSampling        | 10.2     |
| Time-ModelFit           | 3.23     |
| n_timesteps             | 8000     |
--------------------------------------

 ---------------- Iteration 4 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 100 epochs ...
Training DynamicsModel - finished epoch 0 --train loss: 0.0005  valid loss: 0.0008  valid_loss_mov_avg: 0.0012  epoch time: 0.15
Training DynamicsModel - finished epoch 1 --train loss: 0.0006  valid loss: 0.0009  valid_loss_mov_avg: 0.0012  epoch time: 0.16
Training DynamicsModel - finished epoch 2 --train loss: 0.0004  valid loss: 0.0007  valid_loss_mov_avg: 0.0012  epoch time: 0.16
Training DynamicsModel - finished epoch 3 --train loss: 0.0007  valid loss: 0.0003  valid_loss_mov_avg: 0.0012  epoch time: 0.15
Training DynamicsModel - finished epoch 4 --train loss: 0.0002  valid loss: 0.0004  valid_loss_mov_avg: 0.0012  epoch time: 0.16
Training DynamicsModel - finished epoch 5 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0012  epoch time: 0.16
Training DynamicsModel - finished epoch 6 --train loss: 0.0003  valid loss: 0.0002  valid_loss_mov_avg: 0.0012  epoch time: 0.16
Training DynamicsModel - finished epoch 7 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0012  epoch time: 0.15
Training DynamicsModel - finished epoch 8 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0012  epoch time: 0.16
Training DynamicsModel - finished epoch 9 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0011  epoch time: 0.15
Training DynamicsModel - finished epoch 10 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.0011  epoch time: 0.17
Training DynamicsModel - finished epoch 11 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0011  epoch time: 0.16
Training DynamicsModel - finished epoch 12 --train loss: 0.0003  valid loss: 0.0002  valid_loss_mov_avg: 0.0011  epoch time: 0.15
Training DynamicsModel - finished epoch 13 --train loss: 0.0002  valid loss: 0.0004  valid_loss_mov_avg: 0.0011  epoch time: 0.15
Training DynamicsModel - finished epoch 14 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.0011  epoch time: 0.16
Training DynamicsModel - finished epoch 15 --train loss: 0.0003  valid loss: 0.0002  valid_loss_mov_avg: 0.0011  epoch time: 0.16
Training DynamicsModel - finished epoch 16 --train loss: 0.0003  valid loss: 0.0004  valid_loss_mov_avg: 0.0011  epoch time: 0.16
Training DynamicsModel - finished epoch 17 --train loss: 0.0003  valid loss: 0.0002  valid_loss_mov_avg: 0.0011  epoch time: 0.16
Training DynamicsModel - finished epoch 18 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0011  epoch time: 0.16
Training DynamicsModel - finished epoch 19 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0011  epoch time: 0.15
Training DynamicsModel - finished epoch 20 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0011  epoch time: 0.16
Training DynamicsModel - finished epoch 21 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0010  epoch time: 0.15
Training DynamicsModel - finished epoch 22 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0010  epoch time: 0.16
Training DynamicsModel - finished epoch 23 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0010  epoch time: 0.15
Training DynamicsModel - finished epoch 24 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0010  epoch time: 0.16
Training DynamicsModel - finished epoch 25 --train loss: 0.0003  valid loss: 0.0002  valid_loss_mov_avg: 0.0010  epoch time: 0.15
Training DynamicsModel - finished epoch 26 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.0010  epoch time: 0.15
Training DynamicsModel - finished epoch 27 --train loss: 0.0003  valid loss: 0.0002  valid_loss_mov_avg: 0.0010  epoch time: 0.16
Training DynamicsModel - finished epoch 28 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0010  epoch time: 0.15
Training DynamicsModel - finished epoch 29 --train loss: 0.0003  valid loss: 0.0004  valid_loss_mov_avg: 0.0010  epoch time: 0.16
Training DynamicsModel - finished epoch 30 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.0010  epoch time: 0.15
Training DynamicsModel - finished epoch 31 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.0010  epoch time: 0.14
Training DynamicsModel - finished epoch 32 --train loss: 0.0003  valid loss: 0.0002  valid_loss_mov_avg: 0.0010  epoch time: 0.16
Training DynamicsModel - finished epoch 33 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0010  epoch time: 0.15
Training DynamicsModel - finished epoch 34 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0009  epoch time: 0.16
Training DynamicsModel - finished epoch 35 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0009  epoch time: 0.16
Training DynamicsModel - finished epoch 36 --train loss: 0.0003  valid loss: 0.0002  valid_loss_mov_avg: 0.0009  epoch time: 0.16
Training DynamicsModel - finished epoch 37 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.0009  epoch time: 0.16
Training DynamicsModel - finished epoch 38 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0009  epoch time: 0.16
Training DynamicsModel - finished epoch 39 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0009  epoch time: 0.15
Training DynamicsModel - finished epoch 40 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0009  epoch time: 0.15
Training DynamicsModel - finished epoch 41 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0009  epoch time: 0.16
Training DynamicsModel - finished epoch 42 --train loss: 0.0003  valid loss: 0.0004  valid_loss_mov_avg: 0.0009  epoch time: 0.16
Training DynamicsModel - finished epoch 43 --train loss: 0.0002  valid loss: 0.0004  valid_loss_mov_avg: 0.0009  epoch time: 0.15
Training DynamicsModel - finished epoch 44 --train loss: 0.0004  valid loss: 0.0003  valid_loss_mov_avg: 0.0009  epoch time: 0.16
Training DynamicsModel - finished epoch 45 --train loss: 0.0005  valid loss: 0.0002  valid_loss_mov_avg: 0.0009  epoch time: 0.16
Training DynamicsModel - finished epoch 46 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.0009  epoch time: 0.16
Training DynamicsModel - finished epoch 47 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0009  epoch time: 0.16
Training DynamicsModel - finished epoch 48 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.0009  epoch time: 0.15
Training DynamicsModel - finished epoch 49 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0009  epoch time: 0.17
Training DynamicsModel - finished epoch 50 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0008  epoch time: 0.15
Training DynamicsModel - finished epoch 51 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0008  epoch time: 0.15
Training DynamicsModel - finished epoch 52 --train loss: 0.0003  valid loss: 0.0002  valid_loss_mov_avg: 0.0008  epoch time: 0.16
Training DynamicsModel - finished epoch 53 --train loss: 0.0003  valid loss: 0.0005  valid_loss_mov_avg: 0.0008  epoch time: 0.16
Training DynamicsModel - finished epoch 54 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0008  epoch time: 0.15
Training DynamicsModel - finished epoch 55 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0008  epoch time: 0.15
Training DynamicsModel - finished epoch 56 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0008  epoch time: 0.14
Training DynamicsModel - finished epoch 57 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0008  epoch time: 0.16
Training DynamicsModel - finished epoch 58 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0008  epoch time: 0.15
Training DynamicsModel - finished epoch 59 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0008  epoch time: 0.16
Training DynamicsModel - finished epoch 60 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0008  epoch time: 0.16
Training DynamicsModel - finished epoch 61 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0008  epoch time: 0.16
Training DynamicsModel - finished epoch 62 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0008  epoch time: 0.16
Training DynamicsModel - finished epoch 63 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0008  epoch time: 0.15
Training DynamicsModel - finished epoch 64 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.0008  epoch time: 0.16
Training DynamicsModel - finished epoch 65 --train loss: 0.0003  valid loss: 0.0022  valid_loss_mov_avg: 0.0008  epoch time: 0.15
Stopping Training of Model since its valid_loss_rolling_average increased
Evaluating agent...
Saving snapshot...
Saved
--------------------------------------
| AverageDiscountedReturn | 77.9     |
| AverageReturn           | 155      |
| AvgModelEpochTime       | 0.156    |
| EnvExecTime             | 0.321    |
| Epochs                  | 65       |
| Eval-AverageReturn      | 186      |
| Itr                     | 4        |
| ItrTime                 | 50.9     |
| MaxReturn               | 200      |
| MinReturn               | 105      |
| NumTrajs                | 13       |
| PolicyExecTime          | 10       |
| StdReturn               | 32.7     |
| Time                    | 204      |
| Time-AgentEval          | 29.7     |
| Time-EnvSampleProc      | 0.00181  |
| Time-EnvSampling        | 10.4     |
| Time-ModelFit           | 10.8     |
| n_timesteps             | 10000    |
--------------------------------------

 ---------------- Iteration 5 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 100 epochs ...
Training DynamicsModel - finished epoch 0 --train loss: 0.0014  valid loss: 0.0008  valid_loss_mov_avg: 0.0012  epoch time: 0.19
Training DynamicsModel - finished epoch 1 --train loss: 0.0009  valid loss: 0.0008  valid_loss_mov_avg: 0.0012  epoch time: 0.16
Training DynamicsModel - finished epoch 2 --train loss: 0.0005  valid loss: 0.0003  valid_loss_mov_avg: 0.0012  epoch time: 0.18
Training DynamicsModel - finished epoch 3 --train loss: 0.0003  valid loss: 0.0002  valid_loss_mov_avg: 0.0012  epoch time: 0.19
Training DynamicsModel - finished epoch 4 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0012  epoch time: 0.18
Training DynamicsModel - finished epoch 5 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0012  epoch time: 0.19
Training DynamicsModel - finished epoch 6 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0012  epoch time: 0.18
Training DynamicsModel - finished epoch 7 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0012  epoch time: 0.18
Training DynamicsModel - finished epoch 8 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0012  epoch time: 0.18
Training DynamicsModel - finished epoch 9 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0012  epoch time: 0.18
Training DynamicsModel - finished epoch 10 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0011  epoch time: 0.20
Training DynamicsModel - finished epoch 11 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0011  epoch time: 0.19
Training DynamicsModel - finished epoch 12 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0011  epoch time: 0.18
Training DynamicsModel - finished epoch 13 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0011  epoch time: 0.19
Training DynamicsModel - finished epoch 14 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0011  epoch time: 0.18
Training DynamicsModel - finished epoch 15 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0011  epoch time: 0.19
Training DynamicsModel - finished epoch 16 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0011  epoch time: 0.19
Training DynamicsModel - finished epoch 17 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0011  epoch time: 0.18
Training DynamicsModel - finished epoch 18 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0011  epoch time: 0.19
Training DynamicsModel - finished epoch 19 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0011  epoch time: 0.19
Training DynamicsModel - finished epoch 20 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0011  epoch time: 0.19
Training DynamicsModel - finished epoch 21 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0010  epoch time: 0.18
Training DynamicsModel - finished epoch 22 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0010  epoch time: 0.18
Training DynamicsModel - finished epoch 23 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0010  epoch time: 0.18
Training DynamicsModel - finished epoch 24 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0010  epoch time: 0.19
Training DynamicsModel - finished epoch 25 --train loss: 0.0001  valid loss: 0.0003  valid_loss_mov_avg: 0.0010  epoch time: 0.18
Training DynamicsModel - finished epoch 26 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0010  epoch time: 0.18
Training DynamicsModel - finished epoch 27 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0010  epoch time: 0.18
Training DynamicsModel - finished epoch 28 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0010  epoch time: 0.18
Training DynamicsModel - finished epoch 29 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0010  epoch time: 0.19
Training DynamicsModel - finished epoch 30 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0010  epoch time: 0.18
Training DynamicsModel - finished epoch 31 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0010  epoch time: 0.19
Training DynamicsModel - finished epoch 32 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0010  epoch time: 0.19
Training DynamicsModel - finished epoch 33 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0009  epoch time: 0.18
Training DynamicsModel - finished epoch 34 --train loss: 0.0001  valid loss: 0.0004  valid_loss_mov_avg: 0.0009  epoch time: 0.18
Training DynamicsModel - finished epoch 35 --train loss: 0.0004  valid loss: 0.0002  valid_loss_mov_avg: 0.0009  epoch time: 0.18
Training DynamicsModel - finished epoch 36 --train loss: 0.0003  valid loss: 0.0002  valid_loss_mov_avg: 0.0009  epoch time: 0.19
Training DynamicsModel - finished epoch 37 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0009  epoch time: 0.17
Training DynamicsModel - finished epoch 38 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0009  epoch time: 0.19
Training DynamicsModel - finished epoch 39 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0009  epoch time: 0.19
Training DynamicsModel - finished epoch 40 --train loss: 0.0003  valid loss: 0.0004  valid_loss_mov_avg: 0.0009  epoch time: 0.18
Training DynamicsModel - finished epoch 41 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.0009  epoch time: 0.18
Training DynamicsModel - finished epoch 42 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.0009  epoch time: 0.19
Training DynamicsModel - finished epoch 43 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.0009  epoch time: 0.18
Training DynamicsModel - finished epoch 44 --train loss: 0.0003  valid loss: 0.0004  valid_loss_mov_avg: 0.0009  epoch time: 0.19
Training DynamicsModel - finished epoch 45 --train loss: 0.0003  valid loss: 0.0003  valid_loss_mov_avg: 0.0009  epoch time: 0.19
Training DynamicsModel - finished epoch 46 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0009  epoch time: 0.18
Training DynamicsModel - finished epoch 47 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0009  epoch time: 0.18
Training DynamicsModel - finished epoch 48 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0008  epoch time: 0.19
Training DynamicsModel - finished epoch 49 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0008  epoch time: 0.19
Training DynamicsModel - finished epoch 50 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0008  epoch time: 0.17
Training DynamicsModel - finished epoch 51 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0008  epoch time: 0.17
Training DynamicsModel - finished epoch 52 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0008  epoch time: 0.18
Training DynamicsModel - finished epoch 53 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0008  epoch time: 0.19
Training DynamicsModel - finished epoch 54 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0008  epoch time: 0.18
Training DynamicsModel - finished epoch 55 --train loss: 0.0002  valid loss: 0.0004  valid_loss_mov_avg: 0.0008  epoch time: 0.18
Training DynamicsModel - finished epoch 56 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0008  epoch time: 0.18
Training DynamicsModel - finished epoch 57 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0008  epoch time: 0.18
Training DynamicsModel - finished epoch 58 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0008  epoch time: 0.18
Training DynamicsModel - finished epoch 59 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0008  epoch time: 0.18
Training DynamicsModel - finished epoch 60 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0008  epoch time: 0.18
Training DynamicsModel - finished epoch 61 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0008  epoch time: 0.17
Training DynamicsModel - finished epoch 62 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0008  epoch time: 0.19
Training DynamicsModel - finished epoch 63 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0008  epoch time: 0.19
Training DynamicsModel - finished epoch 64 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0007  epoch time: 0.19
Training DynamicsModel - finished epoch 65 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0007  epoch time: 0.19
Training DynamicsModel - finished epoch 66 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0007  epoch time: 0.18
Training DynamicsModel - finished epoch 67 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0007  epoch time: 0.18
Training DynamicsModel - finished epoch 68 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0007  epoch time: 0.19
Training DynamicsModel - finished epoch 69 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0007  epoch time: 0.19
Training DynamicsModel - finished epoch 70 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0007  epoch time: 0.18
Training DynamicsModel - finished epoch 71 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0007  epoch time: 0.18
Training DynamicsModel - finished epoch 72 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0007  epoch time: 0.19
Training DynamicsModel - finished epoch 73 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0007  epoch time: 0.19
Training DynamicsModel - finished epoch 74 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0007  epoch time: 0.17
Training DynamicsModel - finished epoch 75 --train loss: 0.0002  valid loss: 0.0005  valid_loss_mov_avg: 0.0007  epoch time: 0.19
Training DynamicsModel - finished epoch 76 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0007  epoch time: 0.19
Training DynamicsModel - finished epoch 77 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0007  epoch time: 0.19
Training DynamicsModel - finished epoch 78 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0007  epoch time: 0.19
Training DynamicsModel - finished epoch 79 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0007  epoch time: 0.19
Training DynamicsModel - finished epoch 80 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0007  epoch time: 0.19
Training DynamicsModel - finished epoch 81 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0007  epoch time: 0.17
Training DynamicsModel - finished epoch 82 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0007  epoch time: 0.18
Training DynamicsModel - finished epoch 83 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0006  epoch time: 0.18
Training DynamicsModel - finished epoch 84 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0006  epoch time: 0.18
Training DynamicsModel - finished epoch 85 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0006  epoch time: 0.18
Training DynamicsModel - finished epoch 86 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0006  epoch time: 0.19
Training DynamicsModel - finished epoch 87 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0006  epoch time: 0.19
Training DynamicsModel - finished epoch 88 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0006  epoch time: 0.18
Training DynamicsModel - finished epoch 89 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0006  epoch time: 0.19
Training DynamicsModel - finished epoch 90 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0006  epoch time: 0.18
Training DynamicsModel - finished epoch 91 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0006  epoch time: 0.18
Training DynamicsModel - finished epoch 92 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0006  epoch time: 0.19
Training DynamicsModel - finished epoch 93 --train loss: 0.0001  valid loss: 0.0003  valid_loss_mov_avg: 0.0006  epoch time: 0.16
Training DynamicsModel - finished epoch 94 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0006  epoch time: 0.19
Training DynamicsModel - finished epoch 95 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0006  epoch time: 0.19
Training DynamicsModel - finished epoch 96 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0006  epoch time: 0.19
Training DynamicsModel - finished epoch 97 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0006  epoch time: 0.19
Training DynamicsModel - finished epoch 98 --train loss: 0.0001  valid loss: 0.0003  valid_loss_mov_avg: 0.0006  epoch time: 0.19
Training DynamicsModel - finished epoch 99 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0006  epoch time: 0.19
Stopping Training of Model since it reached max epochs
Evaluating agent...
Saving snapshot...
Saved
--------------------------------------
| AverageDiscountedReturn | 78       |
| AverageReturn           | 159      |
| AvgModelEpochTime       | 0.184    |
| EnvExecTime             | 0.355    |
| Epochs                  | 99       |
| Eval-AverageReturn      | 168      |
| Itr                     | 5        |
| ItrTime                 | 58.6     |
| MaxReturn               | 200      |
| MinReturn               | 96       |
| NumTrajs                | 13       |
| PolicyExecTime          | 11.1     |
| StdReturn               | 39.9     |
| Time                    | 263      |
| Time-AgentEval          | 27.9     |
| Time-EnvSampleProc      | 0.00182  |
| Time-EnvSampling        | 11.5     |
| Time-ModelFit           | 19.1     |
| n_timesteps             | 12000    |
--------------------------------------

 ---------------- Iteration 6 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 100 epochs ...
Training DynamicsModel - finished epoch 0 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.21
Training DynamicsModel - finished epoch 1 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0002  epoch time: 0.20
Stopping Training of Model since its valid_loss_rolling_average increased
Evaluating agent...
Saving snapshot...
Saved
--------------------------------------
| AverageDiscountedReturn | 78.1     |
| AverageReturn           | 167      |
| AvgModelEpochTime       | 0.206    |
| EnvExecTime             | 0.368    |
| Epochs                  | 1        |
| Eval-AverageReturn      | 167      |
| Itr                     | 6        |
| ItrTime                 | 39.9     |
| MaxReturn               | 200      |
| MinReturn               | 29       |
| NumTrajs                | 12       |
| PolicyExecTime          | 11.5     |
| StdReturn               | 48.6     |
| Time                    | 303      |
| Time-AgentEval          | 27.5     |
| Time-EnvSampleProc      | 0.00186  |
| Time-EnvSampling        | 12       |
| Time-ModelFit           | 0.432    |
| n_timesteps             | 14000    |
--------------------------------------

 ---------------- Iteration 7 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 100 epochs ...
Training DynamicsModel - finished epoch 0 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.24
Training DynamicsModel - finished epoch 1 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.23
Training DynamicsModel - finished epoch 2 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.24
Training DynamicsModel - finished epoch 3 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.20
Training DynamicsModel - finished epoch 4 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.21
Training DynamicsModel - finished epoch 5 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.24
Training DynamicsModel - finished epoch 6 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.22
Training DynamicsModel - finished epoch 7 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.21
Training DynamicsModel - finished epoch 8 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.24
Training DynamicsModel - finished epoch 9 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.24
Training DynamicsModel - finished epoch 10 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.24
Training DynamicsModel - finished epoch 11 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0002  epoch time: 0.23
Stopping Training of Model since its valid_loss_rolling_average increased
Evaluating agent...
Saving snapshot...
Saved
--------------------------------------
| AverageDiscountedReturn | 76.4     |
| AverageReturn           | 155      |
| AvgModelEpochTime       | 0.229    |
| EnvExecTime             | 0.353    |
| Epochs                  | 11       |
| Eval-AverageReturn      | 164      |
| Itr                     | 7        |
| ItrTime                 | 41.9     |
| MaxReturn               | 200      |
| MinReturn               | 51       |
| NumTrajs                | 13       |
| PolicyExecTime          | 11.1     |
| StdReturn               | 44.9     |
| Time                    | 345      |
| Time-AgentEval          | 27.6     |
| Time-EnvSampleProc      | 0.00182  |
| Time-EnvSampling        | 11.5     |
| Time-ModelFit           | 2.85     |
| n_timesteps             | 16000    |
--------------------------------------

 ---------------- Iteration 8 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 100 epochs ...
Training DynamicsModel - finished epoch 0 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0002  epoch time: 0.27
Training DynamicsModel - finished epoch 1 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0002  epoch time: 0.26
Training DynamicsModel - finished epoch 2 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0002  epoch time: 0.27
Training DynamicsModel - finished epoch 3 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0002  epoch time: 0.26
Training DynamicsModel - finished epoch 4 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.25
Training DynamicsModel - finished epoch 5 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.27
Training DynamicsModel - finished epoch 6 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.26
Training DynamicsModel - finished epoch 7 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0002  epoch time: 0.26
Training DynamicsModel - finished epoch 8 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.26
Training DynamicsModel - finished epoch 9 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0002  epoch time: 0.25
Stopping Training of Model since its valid_loss_rolling_average increased
Evaluating agent...
Saving snapshot...
Saved
--------------------------------------
| AverageDiscountedReturn | 80.5     |
| AverageReturn           | 168      |
| AvgModelEpochTime       | 0.26     |
| EnvExecTime             | 0.362    |
| Epochs                  | 9        |
| Eval-AverageReturn      | 166      |
| Itr                     | 8        |
| ItrTime                 | 41.5     |
| MaxReturn               | 200      |
| MinReturn               | 113      |
| NumTrajs                | 12       |
| PolicyExecTime          | 11.4     |
| StdReturn               | 30.3     |
| Time                    | 386      |
| Time-AgentEval          | 26.9     |
| Time-EnvSampleProc      | 0.00418  |
| Time-EnvSampling        | 11.8     |
| Time-ModelFit           | 2.69     |
| n_timesteps             | 18000    |
--------------------------------------

 ---------------- Iteration 9 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 100 epochs ...
Training DynamicsModel - finished epoch 0 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.28
Training DynamicsModel - finished epoch 1 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.29
Training DynamicsModel - finished epoch 2 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.27
Training DynamicsModel - finished epoch 3 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.27
Training DynamicsModel - finished epoch 4 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.26
Training DynamicsModel - finished epoch 5 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.26
Training DynamicsModel - finished epoch 6 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0002  epoch time: 0.28
Stopping Training of Model since its valid_loss_rolling_average increased
Evaluating agent...
Saving snapshot...
Saved
--------------------------------------
| AverageDiscountedReturn | 84       |
| AverageReturn           | 186      |
| AvgModelEpochTime       | 0.274    |
| EnvExecTime             | 0.336    |
| Epochs                  | 6        |
| Eval-AverageReturn      | 180      |
| Itr                     | 9        |
| ItrTime                 | 42       |
| MaxReturn               | 200      |
| MinReturn               | 113      |
| NumTrajs                | 11       |
| PolicyExecTime          | 10.7     |
| StdReturn               | 25.4     |
| Time                    | 428      |
| Time-AgentEval          | 28.9     |
| Time-EnvSampleProc      | 0.00189  |
| Time-EnvSampling        | 11.1     |
| Time-ModelFit           | 1.98     |
| n_timesteps             | 20000    |
--------------------------------------

 ---------------- Iteration 10 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 100 epochs ...
Training DynamicsModel - finished epoch 0 --train loss: 0.0002  valid loss: 0.0004  valid_loss_mov_avg: 0.0005  epoch time: 0.32
Training DynamicsModel - finished epoch 1 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.30
Training DynamicsModel - finished epoch 2 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.33
Training DynamicsModel - finished epoch 3 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0005  epoch time: 0.32
Training DynamicsModel - finished epoch 4 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.32
Training DynamicsModel - finished epoch 5 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0005  epoch time: 0.32
Training DynamicsModel - finished epoch 6 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.32
Training DynamicsModel - finished epoch 7 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0005  epoch time: 0.32
Training DynamicsModel - finished epoch 8 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.33
Training DynamicsModel - finished epoch 9 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.32
Training DynamicsModel - finished epoch 10 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0005  epoch time: 0.32
Training DynamicsModel - finished epoch 11 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.33
Training DynamicsModel - finished epoch 12 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.33
Training DynamicsModel - finished epoch 13 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0005  epoch time: 0.33
Training DynamicsModel - finished epoch 14 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0005  epoch time: 0.32
Training DynamicsModel - finished epoch 15 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0005  epoch time: 0.32
Training DynamicsModel - finished epoch 16 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.32
Training DynamicsModel - finished epoch 17 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.32
Training DynamicsModel - finished epoch 18 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.32
Training DynamicsModel - finished epoch 19 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.32
Training DynamicsModel - finished epoch 20 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.30
Training DynamicsModel - finished epoch 21 --train loss: 0.0001  valid loss: 0.0003  valid_loss_mov_avg: 0.0005  epoch time: 0.32
Training DynamicsModel - finished epoch 22 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0005  epoch time: 0.33
Training DynamicsModel - finished epoch 23 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0005  epoch time: 0.32
Training DynamicsModel - finished epoch 24 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0004  epoch time: 0.31
Training DynamicsModel - finished epoch 25 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0004  epoch time: 0.32
Training DynamicsModel - finished epoch 26 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0004  epoch time: 0.30
Training DynamicsModel - finished epoch 27 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0004  epoch time: 0.33
Training DynamicsModel - finished epoch 28 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0004  epoch time: 0.31
Training DynamicsModel - finished epoch 29 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0004  epoch time: 0.32
Training DynamicsModel - finished epoch 30 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0004  epoch time: 0.32
Training DynamicsModel - finished epoch 31 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0004  epoch time: 0.31
Training DynamicsModel - finished epoch 32 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0004  epoch time: 0.29
Training DynamicsModel - finished epoch 33 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0004  epoch time: 0.28
Training DynamicsModel - finished epoch 34 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0004  epoch time: 0.32
Training DynamicsModel - finished epoch 35 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0004  epoch time: 0.31
Training DynamicsModel - finished epoch 36 --train loss: 0.0001  valid loss: 0.0004  valid_loss_mov_avg: 0.0004  epoch time: 0.30
Stopping Training of Model since its valid_loss_rolling_average increased
Evaluating agent...
Saving snapshot...
Saved
--------------------------------------
| AverageDiscountedReturn | 84       |
| AverageReturn           | 188      |
| AvgModelEpochTime       | 0.316    |
| EnvExecTime             | 0.353    |
| Epochs                  | 36       |
| Eval-AverageReturn      | 168      |
| Itr                     | 10       |
| ItrTime                 | 49.7     |
| MaxReturn               | 200      |
| MinReturn               | 102      |
| NumTrajs                | 11       |
| PolicyExecTime          | 11.2     |
| StdReturn               | 29.2     |
| Time                    | 478      |
| Time-AgentEval          | 26.1     |
| Time-EnvSampleProc      | 0.00181  |
| Time-EnvSampling        | 11.6     |
| Time-ModelFit           | 12       |
| n_timesteps             | 22000    |
--------------------------------------

 ---------------- Iteration 11 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 100 epochs ...
Training DynamicsModel - finished epoch 0 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0001  epoch time: 0.35
Training DynamicsModel - finished epoch 1 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0001  epoch time: 0.33
Training DynamicsModel - finished epoch 2 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0001  epoch time: 0.34
Training DynamicsModel - finished epoch 3 --train loss: 0.0001  valid loss: 0.0003  valid_loss_mov_avg: 0.0001  epoch time: 0.35
Stopping Training of Model since its valid_loss_rolling_average increased
Evaluating agent...
Saving snapshot...
Saved
--------------------------------------
| AverageDiscountedReturn | 83.3     |
| AverageReturn           | 182      |
| AvgModelEpochTime       | 0.338    |
| EnvExecTime             | 0.409    |
| Epochs                  | 3        |
| Eval-AverageReturn      | 172      |
| Itr                     | 11       |
| ItrTime                 | 43.3     |
| MaxReturn               | 200      |
| MinReturn               | 128      |
| NumTrajs                | 12       |
| PolicyExecTime          | 12.9     |
| StdReturn               | 24.2     |
| Time                    | 521      |
| Time-AgentEval          | 28.6     |
| Time-EnvSampleProc      | 0.00189  |
| Time-EnvSampling        | 13.3     |
| Time-ModelFit           | 1.39     |
| n_timesteps             | 24000    |
--------------------------------------

 ---------------- Iteration 12 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 100 epochs ...
Training DynamicsModel - finished epoch 0 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0001  epoch time: 0.35
Training DynamicsModel - finished epoch 1 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0001  epoch time: 0.38
Stopping Training of Model since its valid_loss_rolling_average increased
Evaluating agent...
Saving snapshot...
Saved
--------------------------------------
| AverageDiscountedReturn | 80.3     |
| AverageReturn           | 165      |
| AvgModelEpochTime       | 0.37     |
| EnvExecTime             | 0.388    |
| Epochs                  | 1        |
| Eval-AverageReturn      | 178      |
| Itr                     | 12       |
| ItrTime                 | 42.9     |
| MaxReturn               | 200      |
| MinReturn               | 127      |
| NumTrajs                | 13       |
| PolicyExecTime          | 12.2     |
| StdReturn               | 26.5     |
| Time                    | 564      |
| Time-AgentEval          | 29.6     |
| Time-EnvSampleProc      | 0.00193  |
| Time-EnvSampling        | 12.6     |
| Time-ModelFit           | 0.762    |
| n_timesteps             | 26000    |
--------------------------------------

 ---------------- Iteration 13 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 100 epochs ...
Training DynamicsModel - finished epoch 0 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0001  epoch time: 0.41
Training DynamicsModel - finished epoch 1 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0001  epoch time: 0.41
Training DynamicsModel - finished epoch 2 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0001  epoch time: 0.39
Training DynamicsModel - finished epoch 3 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0001  epoch time: 0.41
Stopping Training of Model since its valid_loss_rolling_average increased
Evaluating agent...
Saving snapshot...
Saved
--------------------------------------
| AverageDiscountedReturn | 80.3     |
| AverageReturn           | 167      |
| AvgModelEpochTime       | 0.402    |
| EnvExecTime             | 0.355    |
| Epochs                  | 3        |
| Eval-AverageReturn      | 172      |
| Itr                     | 13       |
| ItrTime                 | 39.8     |
| MaxReturn               | 200      |
| MinReturn               | 116      |
| NumTrajs                | 12       |
| PolicyExecTime          | 11.2     |
| StdReturn               | 31.1     |
| Time                    | 604      |
| Time-AgentEval          | 26.6     |
| Time-EnvSampleProc      | 0.00184  |
| Time-EnvSampling        | 11.6     |
| Time-ModelFit           | 1.65     |
| n_timesteps             | 28000    |
--------------------------------------

 ---------------- Iteration 14 ----------------
Obtaining samples from the environment using the policy...
Processing environment samples...
Training dynamics model for 100 epochs ...
Training DynamicsModel - finished epoch 0 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0003  epoch time: 0.42
Training DynamicsModel - finished epoch 1 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0003  epoch time: 0.43
Training DynamicsModel - finished epoch 2 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.42
Training DynamicsModel - finished epoch 3 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0003  epoch time: 0.43
Training DynamicsModel - finished epoch 4 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.42
Training DynamicsModel - finished epoch 5 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.42
Training DynamicsModel - finished epoch 6 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.44
Training DynamicsModel - finished epoch 7 --train loss: 0.0002  valid loss: 0.0003  valid_loss_mov_avg: 0.0003  epoch time: 0.43
Training DynamicsModel - finished epoch 8 --train loss: 0.0002  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.42
Training DynamicsModel - finished epoch 9 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.42
Training DynamicsModel - finished epoch 10 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.42
Training DynamicsModel - finished epoch 11 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0003  epoch time: 0.41
Training DynamicsModel - finished epoch 12 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.43
Training DynamicsModel - finished epoch 13 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0003  epoch time: 0.43
Training DynamicsModel - finished epoch 14 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.44
Training DynamicsModel - finished epoch 15 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0003  epoch time: 0.43
Training DynamicsModel - finished epoch 16 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0003  epoch time: 0.43
Training DynamicsModel - finished epoch 17 --train loss: 0.0001  valid loss: 0.0000  valid_loss_mov_avg: 0.0003  epoch time: 0.40
Training DynamicsModel - finished epoch 18 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.43
Training DynamicsModel - finished epoch 19 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0003  epoch time: 0.42
Training DynamicsModel - finished epoch 20 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.42
Training DynamicsModel - finished epoch 21 --train loss: 0.0002  valid loss: 0.0002  valid_loss_mov_avg: 0.0003  epoch time: 0.41
Training DynamicsModel - finished epoch 22 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.42
Training DynamicsModel - finished epoch 23 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.43
Training DynamicsModel - finished epoch 24 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.42
Training DynamicsModel - finished epoch 25 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.43
Training DynamicsModel - finished epoch 26 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.42
Training DynamicsModel - finished epoch 27 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0003  epoch time: 0.43
Training DynamicsModel - finished epoch 28 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0003  epoch time: 0.41
Training DynamicsModel - finished epoch 29 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0003  epoch time: 0.38
Training DynamicsModel - finished epoch 30 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.41
Training DynamicsModel - finished epoch 31 --train loss: 0.0001  valid loss: 0.0000  valid_loss_mov_avg: 0.0003  epoch time: 0.41
Training DynamicsModel - finished epoch 32 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.41
Training DynamicsModel - finished epoch 33 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.43
Training DynamicsModel - finished epoch 34 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.43
Training DynamicsModel - finished epoch 35 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.41
Training DynamicsModel - finished epoch 36 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0003  epoch time: 0.43
Training DynamicsModel - finished epoch 37 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.40
Training DynamicsModel - finished epoch 38 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.43
Training DynamicsModel - finished epoch 39 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0003  epoch time: 0.43
Training DynamicsModel - finished epoch 40 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 41 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.44
Training DynamicsModel - finished epoch 42 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.44
Training DynamicsModel - finished epoch 43 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0002  epoch time: 0.44
Training DynamicsModel - finished epoch 44 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.41
Training DynamicsModel - finished epoch 45 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.42
Training DynamicsModel - finished epoch 46 --train loss: 0.0001  valid loss: 0.0000  valid_loss_mov_avg: 0.0002  epoch time: 0.42
Training DynamicsModel - finished epoch 47 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 48 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 49 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.41
Training DynamicsModel - finished epoch 50 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.42
Training DynamicsModel - finished epoch 51 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0002  epoch time: 0.41
Training DynamicsModel - finished epoch 52 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 53 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.44
Training DynamicsModel - finished epoch 54 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.42
Training DynamicsModel - finished epoch 55 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.42
Training DynamicsModel - finished epoch 56 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.41
Training DynamicsModel - finished epoch 57 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 58 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 59 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 60 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.44
Training DynamicsModel - finished epoch 61 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.44
Training DynamicsModel - finished epoch 62 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 63 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.41
Training DynamicsModel - finished epoch 64 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.40
Training DynamicsModel - finished epoch 65 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.42
Training DynamicsModel - finished epoch 66 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 67 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.42
Training DynamicsModel - finished epoch 68 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.42
Training DynamicsModel - finished epoch 69 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 70 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.42
Training DynamicsModel - finished epoch 71 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 72 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.42
Training DynamicsModel - finished epoch 73 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.42
Training DynamicsModel - finished epoch 74 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.44
Training DynamicsModel - finished epoch 75 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 76 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.42
Training DynamicsModel - finished epoch 77 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.42
Training DynamicsModel - finished epoch 78 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.45
Training DynamicsModel - finished epoch 79 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 80 --train loss: 0.0001  valid loss: 0.0000  valid_loss_mov_avg: 0.0002  epoch time: 0.41
Training DynamicsModel - finished epoch 81 --train loss: 0.0001  valid loss: 0.0000  valid_loss_mov_avg: 0.0002  epoch time: 0.44
Training DynamicsModel - finished epoch 82 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.42
Training DynamicsModel - finished epoch 83 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0002  epoch time: 0.44
Training DynamicsModel - finished epoch 84 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 85 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 86 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.40
Training DynamicsModel - finished epoch 87 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.41
Training DynamicsModel - finished epoch 88 --train loss: 0.0001  valid loss: 0.0002  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 89 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 90 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.42
Training DynamicsModel - finished epoch 91 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 92 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.43
Training DynamicsModel - finished epoch 93 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.44
Training DynamicsModel - finished epoch 94 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.41
Training DynamicsModel - finished epoch 95 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.44
Training DynamicsModel - finished epoch 96 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.42
Training DynamicsModel - finished epoch 97 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.42
Training DynamicsModel - finished epoch 98 --train loss: 0.0001  valid loss: 0.0001  valid_loss_mov_avg: 0.0002  epoch time: 0.42
Training DynamicsModel - finished epoch 99 --train loss: 0.0001  valid loss: 0.0000  valid_loss_mov_avg: 0.0002  epoch time: 0.40
Stopping Training of Model since it reached max epochs
Evaluating agent...
Saving snapshot...
Saved
--------------------------------------
| AverageDiscountedReturn | 80.8     |
| AverageReturn           | 170      |
| AvgModelEpochTime       | 0.423    |
| EnvExecTime             | 0.359    |
| Epochs                  | 99       |
| Eval-AverageReturn      | 170      |
| Itr                     | 14       |
| ItrTime                 | 82.7     |
| MaxReturn               | 200      |
| MinReturn               | 110      |
| NumTrajs                | 12       |
| PolicyExecTime          | 11.3     |
| StdReturn               | 32.7     |
| Time                    | 687      |
| Time-AgentEval          | 27.8     |
| Time-EnvSampleProc      | 0.00181  |
| Time-EnvSampling        | 11.7     |
| Time-ModelFit           | 43.2     |
| n_timesteps             | 30000    |
--------------------------------------
Training finished
